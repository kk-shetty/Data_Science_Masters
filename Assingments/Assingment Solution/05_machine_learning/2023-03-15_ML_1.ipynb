{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1. Explain the following with an example:\n",
    "1. **Artificial Intelligence**\n",
    "2. **Machine Learning**\n",
    "3. **Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">1. **Artificial Intelligence (AI)**: \n",
    ">    * Artificial Intelligence refers to the simulation of human intelligence in machines that are capable of performing tasks thattypically requires human intelligence.\n",
    ">    * These tasks includes problem-solving, reasoning, understanding natural language, recognizing patterns and making decisions. \n",
    ">    * AI system aims to mimic cognitive functions in machines\n",
    ">    * **Examples**: Chatbot is an AI system that can understand user's queries, interpret the context and provide relevant responses in real-time simulating human like conversation.\n",
    ">2. **Machine Learning (ML)**:\n",
    ">    * Machine learning is a subset of AI thet involves use of algorithms and statistical  models to enable machines to improve their performance on a task through experience. \n",
    ">    * Instead of being explicitly programmed, machines learn from data and adapt their behaviour over time.\n",
    ">    * **Example**: Consider an email spam filter. Initially, the filter might not accurately distinguish between spam and legitimate emails. With machine learning, it can be trained using a dataset of labeled emails. Over time, it learns to identify patterns associated with spam emails and becomes more accurate in classifying incoming emails as spam or not.\n",
    ">3. **Deep Learning (DL)**: \n",
    ">    * Deep learning i8s a specialized subset of machine learning that focuses on using artificial neural network to model and solve complex problems.\n",
    ">    * The neural network have multiple layesrs (hence \"deep\"), allowingb tyhem to automatically learn intricate features from data and make highly accurate predictions or decisions.\n",
    ">    * **Example**: Image recognition is a prime example of deep learning. Let's take a scenario of identifying cats and dogs in pictures. A deep learning model, like a Convolutional Neural Network (CNN), can learn to detect various features (edges, textures, shapes) of cats and dogs from a large dataset of labeled images. As it processes more data, it becomes proficient at recognizing these animals even in new, unseen images.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2. What is supervised learning? List some examples of supervised learning.\n",
    ">* Supervised learning is a type of machine learning where alogorithms learn from labeled training data to make predictions or decisions.\n",
    ">* In supervised learning , the training data consists of input-output pairs, where the aalgorithms learns to map inputs to corresponding outputs.\n",
    ">* The goal is to generalize these mappings to make accurate predictions on new, unseen data.\n",
    ">* Examples:\n",
    ">   1. **Image Clssification**: Given a dataset of images labeled with corresponding categories (e.g., \"cat\" or \"dog\"), a supervised learning algorithm can learn to classify new images into these categories. This is commonly used in applications like identifying objects in photos, medical image analysis, and quality control in manufacturing.\n",
    ">   2. **Spam Email Detection**: In this case, the algorithm is trained on a labeled dataset of emails marked as spam or not spam. It learns to identify patterns and features in the email content to predict whether an incoming email is spam or not.\n",
    ">   3. **Sentiment Analysis**: Supervised learning can be used to analyze the sentiment expressed in text. For instance, a model can be trained on a dataset of text reviews labeled as positive, negative, or neutral. This enables the model to predict the sentiment of new text inputs.\n",
    ">   4. **Credit Risk Assessment**: Banks and financial institutions use supervised learning to assess the credit risk of loan applicants. The algorithm learns from historical data about past applicants' credit histories and outcomes to predict whether a new applicant is likely to default on a loan. \n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3. What is unsupervised learning? List some examples of unsupervised learning.\n",
    ">* Unsupervised learning is a type of machine learning where the algorithm is given a dataset without explicit labels or target outputs. The goal of unsupervised learning is to dicover pattertns, structures and relationships within the data.\n",
    ">* Unsupervised learning involves exploring inherent structure of the data to find meaningful insights.\n",
    ">* Example:\n",
    ">   1. **Clustering**: Clustering involves grouping similar data points together in clusters based on their features or attributes. The algorithm identifies natural groupings within the data without being provided specific labels. An example is customer segmentation, where data about customer behavior is clustered to identify different customer segments for targeted marketing strategies.\n",
    ">   2. **Anomaly Detection**: Unsupervised learning can be used to identify rare or anomalous data points that differ significantly from the majority. This is useful in fraud detection, where unusual patterns in financial transactions can indicate potential fraud.\n",
    ">   3. **Dimensionality Reduction**: In cases where data has a large number of features, unsupervised learning can be used to reduce the dimensionality of the data while retaining important information. Techniques like Principal Component Analysis (PCA) aim to capture the most important features that explain the variance in the data.\n",
    ">   4. **Image Compression**: Unsupervised learning techniques can be used to compress image data by representing it in a more compact form while preserving essential features.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4. What is the difference between AI, ML, DL, and DS?\n",
    "\n",
    "|AI (Artificial Intelligence)|ML (Machine Learning)|DL (Deep Learning)|DS (Data Science)|\n",
    "|:---------------------------|:--------------------|:-----------------|:----------------|\n",
    "|AI refers to the broader field of enabling machines to perform tasks that typically require human intelligence, such as problem-solving, reasoning, learning, understanding natural language, and making decisions.|Machine Learning is a subset of AI that focuses on the development of algorithms that allow machines to learn from data and improve their performance on a task over time.|Deep Learning is a subset of machine learning that involves using artificial neural networks with multiple layers (deep architectures) to model and solve complex problems.|Data Science is a multidisciplinary field that involves extracting insights and knowledge from data using various techniques, algorithms, and processes.|\n",
    "|AI encompasses various techniques, including machine learning and deep learning, as well as rule-based systems and expert systems.|ML algorithms are designed to recognize patterns and make predictions or decisions without being explicitly programmed. It includes techniques like supervised learning, unsupervised learning, reinforcement learning, and more.|Deep learning has demonstrated exceptional performance in tasks such as image and speech recognition, natural language processing, and playing games. It relies on large amounts of data and computational power to automatically learn features from the data.|It encompasses tasks such as data collection, data cleaning, data analysis, data visualization, and the application of machine learning and statistical methods to solve real-world problems.|\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5. What are the main differences between supervised, unsupervised, and semi-supervised learning?\n",
    "* Supervised, unsupervised, and semi-supervised learning are three different approaches in machine learning that involve different types of data and learning processes. Here are the main differences between them:\n",
    "\n",
    "||Supervised Learning|Unsupervised Learning|Semi-Supervised Learning|\n",
    "|:-|:------------------|:--------------------|:------------------------|\n",
    "|*Data Type*|In supervised learning, the algorithm is trained on a labeled dataset, which means each data point has corresponding target outputs or labels.|In unsupervised learning, the algorithm is trained on an unlabeled dataset, where data points have no associated target outputs or labels.|Semi-supervised learning uses a combination of labeled and unlabeled data for training.|\n",
    "|*Learning Process*|The algorithm learns to map input features to the correct output labels by minimizing the difference between predicted outputs and actual labels.|The algorithm aims to uncover patterns, structures, or relationships within the data. It identifies clusters, groups, or other meaningful representations in the data.|The algorithm leverages the labeled data to learn patterns and relationships, and it also uses the unlabeled data to enhance its understanding of the data's structure.|\n",
    "|*Objective*|The goal is to learn a mapping function that can accurately predict the correct output labels for new, unseen data.| The primary goal is to explore and understand the inherent structure of the data and derive insights from it.|The goal is to make use of both labeled and unlabeled data to improve the model's performance, especially in cases where obtaining labeled data is expensive or time-consuming.|\n",
    "|*Examples*|Classification (assigning categories to inputs) and regression (predicting continuous values) are common tasks in supervised learning.|Clustering (grouping similar data points), dimensionality reduction (reducing the number of features while preserving important information), and anomaly detection (identifying rare or abnormal data points) are common tasks in unsupervised learning.|Semi-supervised learning can be applied to scenarios where acquiring labeled data is challenging but there's a substantial amount of unlabeled data available.|\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q6. What is train, test and validation split? Explain the importance of each term.\n",
    "* The train-test-validation split is a fundamental concept in machine learning and data analysis that involves dividing a dataset into separate subsets for different purposes during model development and evaluation. \n",
    "* Each subset serves a specific role in training, fine-tuning, and assessing the performance of a machine learning model.\n",
    "1. **Training Set**:\n",
    "    * The training set is the largest portion of the dataset and is used to train the machine learning model.\n",
    "    * The model learns patterns, realtionnships and features frtom  training data to make predictions.\n",
    "    * The tyraining set is crucial for teaching the model how to generalize from the data, enabling it to perform well on unseen examples.\n",
    "2. **Validation Set**:\n",
    "    * The validation set is a smnaller subset oif dataset that is not used during the training phase.\n",
    "    * It is used to finetune hyperparametres and access the performance of the model during training.\n",
    "    * The validation set helps prevent overfitting, a situation where the model peforms well on training data but poorly on new data. By tuning hyperparameters based on the validation set's performance, the model can generalize better.\n",
    "3. **Test Set**:\n",
    "    * The test set is a separate portion of the dataset that the model has never seen before.\n",
    "    * It is used to evaluate the final performance of the model, providing an estimate of it's real-world performance.\n",
    "    * The test set helps assess how well the model generalizes to new, unseen data. It provides an unbiased evaluation of the model's performance and helps prevent \"data snooping\" where decisions are made based on test-like data.\n",
    "* **Note**:\n",
    "    1. It's important to maintain the separation between these sets to avoid introducing bias or prematurely evaluating a model's performance. \n",
    "    2. The split ratios can vary, but common splits are 70-15-15 or 80-10-10 for train-validation-test, respectively.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q7. How can unsupervised learning be used in anomaly detection?\n",
    "* Anomalies are instances that deviate significantly from the expected behavior of the majority of the data. \n",
    "* Unsupervised learning is commonly used in anomaly detection to identify rare or abnormal patterns within data. \n",
    "* Unsupervised learning techniques excel at anomaly detection because they can discover patterns without relying on labeled anomaly data.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q8. List down some commonly used supervised learning algorithms and unsupervised learning algorithms.\n",
    "* **Supervised Learning Algorithms:**\n",
    "    1. **Linear Regression:** A simple algorithm for predicting a continuous target variable based on one or more input features.\n",
    "    2. **Logistic Regression:** Used for binary classification, it models the probability of a data point belonging to a particular class.\n",
    "    3. **Decision Trees:** These create a tree-like model of decisions and their possible consequences, often used for classification and regression tasks.\n",
    "    4. **Random Forest:** An ensemble of decision trees that improves robustness and accuracy by averaging predictions from multiple trees.\n",
    "    5. **Support Vector Machines (SVM):** A powerful algorithm for both classification and regression tasks, focusing on finding the optimal decision boundary.\n",
    "    6. **K-Nearest Neighbors (KNN):** Classifies a data point based on the majority class of its k-nearest neighbors in the feature space.\n",
    "    7. **Naive Bayes:** A probabilistic algorithm that applies Bayes' theorem to classify data points based on the probability of class membership given input features.\n",
    "    8. **Gradient Boosting:** An ensemble technique that builds a strong predictive model by combining multiple weak models (often decision trees) in a sequential manner.\n",
    "    9. **Neural Networks:** Complex models inspired by the human brain, used for tasks ranging from image and speech recognition to natural language processing.\n",
    "\n",
    "* **Unsupervised Learning Algorithms:**\n",
    "    1. **K-Means Clustering:** Divides data points into k clusters based on similarity, with each cluster represented by its centroid.\n",
    "    2. **Hierarchical Clustering:** Creates a hierarchy of nested clusters by iteratively merging or splitting clusters based on certain criteria.\n",
    "    3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise):** Identifies dense regions of data points and considers low-density regions as outliers.\n",
    "    4. **PCA (Principal Component Analysis):** A dimensionality reduction technique that transforms data into a new coordinate system to capture the most significant variations.\n",
    "    5. **Autoencoders:** A type of neural network used for unsupervised representation learning, often applied in dimensionality reduction or feature learning.\n",
    "    6. **Gaussian Mixture Models (GMM):** A probabilistic model representing data as a mixture of several Gaussian distributions, useful for modeling complex data distributions.\n",
    "    7. **Isolation Forest:** A tree-based algorithm that isolates anomalies by creating trees that can quickly isolate anomalous observations.\n",
    "    8. **Anomaly Detection with Autoencoders:** Autoencoders are used to learn a compact representation of normal data, and anomalies are identified as data points with high reconstruction errors.\n",
    "    9. **Latent Dirichlet Allocation (LDA):** A generative model that discovers topics within a collection of documents and assigns topics to individual documents.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
